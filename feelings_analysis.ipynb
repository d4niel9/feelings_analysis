{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install googletrans==3.1.0a0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0ARxmHcq-PU",
        "outputId": "a4c608f7-5b43-432a-8c2b-20980b8b02bc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: googletrans==3.1.0a0 in /usr/local/lib/python3.8/dist-packages (3.1.0a0)\n",
            "Requirement already satisfied: httpx==0.13.3 in /usr/local/lib/python3.8/dist-packages (from googletrans==3.1.0a0) (0.13.3)\n",
            "Requirement already satisfied: httpcore==0.9.* in /usr/local/lib/python3.8/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (0.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2022.12.7)\n",
            "Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.8/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (1.5.0)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.8/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2.10)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.8/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (3.0.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.8/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (1.3.0)\n",
            "Requirement already satisfied: hstspreload in /usr/local/lib/python3.8/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2023.1.1)\n",
            "Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.8/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (0.9.0)\n",
            "Requirement already satisfied: h2==3.* in /usr/local/lib/python3.8/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (3.2.0)\n",
            "Requirement already satisfied: hyperframe<6,>=5.2.0 in /usr/local/lib/python3.8/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (5.2.0)\n",
            "Requirement already satisfied: hpack<4,>=3.0 in /usr/local/lib/python3.8/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (3.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Ul3YW3t-qUfY"
      },
      "outputs": [],
      "source": [
        "from googletrans import Translator\n",
        "import os\n",
        "\n",
        "# Language processing\n",
        "import nltk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from nltk import sentiment\n",
        "from nltk import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('vader_lexicon')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmQvl00rcl1e",
        "outputId": "fea75534-b50d-490e-f4c0-54fd7bcb55eb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "analizador = SentimentIntensityAnalyzer()\n",
        "\n",
        "translator = Translator()"
      ],
      "metadata": {
        "id": "covpRLSJco3y"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = \"/content/texto.txt\"\n",
        "\n",
        "def analyze_emotions_text(file):\n",
        "\n",
        "    with open(file,\"r\") as file:\n",
        "        cont = 0\n",
        "        translate = []\n",
        "        for row in file:\n",
        "            cont += 1\n",
        "            print(row)\n",
        "            # Translate es_en\n",
        "            translate_row = translator.translate(row, src=\"es\", dest=\"en\")\n",
        "            row_en = translate_row.text\n",
        "            print(row_en)\n",
        "\n",
        "            # Analisis emotion\n",
        "            scores = analizador.polarity_scores(row_en)\n",
        "            if scores[\"compound\"] > 0:\n",
        "                print(scores[\"compound\"], \"positive\")\n",
        "                print('###########################################')\n",
        "            elif scores[\"compound\"] < 0:\n",
        "              print(scores[\"compound\"], \"negative\")\n",
        "              print('###########################################')\n",
        "            elif scores[\"compound\"] == 0:\n",
        "              print(scores[\"compound\"], \"neutral\")\n",
        "              print('###########################################')\n",
        "\n",
        "\n",
        "    print('Total lines: ', cont)\n",
        "    print('---------------------------------------------------')\n",
        "\n",
        "\n",
        "    \n",
        "analyze_emotions_text(file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgJsZvBwcsE9",
        "outputId": "9f6effdf-f9cd-4e3d-e2f4-039f72d9cbd8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Este script me gusta mucho\n",
            "\n",
            "I like this script a lot\n",
            "0.3612 positive\n",
            "###########################################\n",
            "Script de mierda\n",
            "\n",
            "shitty script\n",
            "-0.5574 negative\n",
            "###########################################\n",
            "Me siento felÃ­z\n",
            "\n",
            "I feel happy\n",
            "0.5719 positive\n",
            "###########################################\n",
            "Me lleva la chingada\n",
            "\n",
            "It takes me the fuck\n",
            "-0.5423 negative\n",
            "###########################################\n",
            "ok\n",
            "\n",
            "okay\n",
            "0.2263 positive\n",
            "###########################################\n",
            "estoy neutral\n",
            "i am neutral\n",
            "0.0 neutral\n",
            "###########################################\n",
            "Total lines:  6\n",
            "---------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WgAuu10PcupC"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}